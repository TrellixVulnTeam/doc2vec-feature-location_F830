


%
%  Describe deep learning for natural language
Statistical natural language models, such as the n-gram model, have
seen widespread use for a variety of natural language processing task
due to their similicity and effectiveness when trained with a
substantial corpus of text. More recent research in this field has
proposed certain classes and architectures of neural networks that can
produce excellent statistical models of natural language text, which
can include deeper contexts and capture more complex patterns, while
trained using smaller corpora, relative to the n-gram model. Using a
set of optimizations strategies such models can be built at reasonable
computational costs for even large textual corpora.


%  ii.) What is related work using deep learnign in SE?
%    in S.E. White's paper

White et al. reported very promising results in applying deep learning
models for source code, outperforming models based on similar n-gram
configurations, even with the use of a large contextual cache. They
sketch out several avenues for future use of such models, including
code completion and the building of synonym dictionaries. Our work
applies this initial research for the feature location problem, and
trains these models on the identifiers and comments in the code only,
and not the entire source listing.




%  iii.) Context based approaches to feature location
%	*Emily Hill et al. “One the use of Positional Proximity for IR-Based Feature Location”
%       *Shepherd
%       *SWUM
%       *Naturalness


hill~\cite{hill_use_2014}
