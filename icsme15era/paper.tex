\documentclass[conference]{IEEEtran}

\makeatletter
% IEEEtran.cls defines \labelindent for backward compatibility reasons
% Undefine \labelindent to allow the use of package enumitem
\let\labelindent\relax
\makeatother


\usepackage[font=small]{caption}
\usepackage[T1]{fontenc}
\usepackage[para]{footmisc}
\usepackage[pdftex]{graphicx}
\usepackage[utf8]{inputenc}
\usepackage{array}
\usepackage{balance}
\usepackage{booktabs}
\usepackage{cite}
\usepackage{color}
\usepackage{comment}
\usepackage{enumitem}
\usepackage{framed}
\usepackage{listings}
\usepackage{microtype}
\usepackage{subcaption}
\usepackage{url}

% makes floatrow put crap on the same row


% SQUEEZE
%\addtolength{\parskip}{-1pt}


\definecolor{lightred}{RGB}{150,0,0}
\definecolor{lightgreen}{RGB}{0,150,0}
\definecolor{lightblue}{RGB}{0,0,150}

\lstdefinelanguage{diff}{
  morecomment=[f][\color{lightblue}]{diff },
  morecomment=[f][\color{lightblue}]{index },
  morecomment=[f][\color{lightblue}]{@@},     % group identifier
  morecomment=[f][\color{lightred}]-,         % deleted lines
  morecomment=[f][\color{lightgreen}]+,       % added lines
  morecomment=[f][\color{lightblue}]{---},    % Diff header lines (must appear after +,-)
  morecomment=[f][\color{lightblue}]{+++},
}
\hyphenation{}

\newcommand{\attn}[1]{{\color{red}#1}}
\newcommand{\desc}[1]{{\emph{\color{blue}#1}}}
\newcommand{\needcite}{\attn{\tiny{[cite]}}}
\newcommand{\todo}[1]{\strut\smash{\colorbox{yellow}{\bf TODO: #1}}}
\setlength\OuterFrameSep{0.5em}
\setlength\FrameSep{0.5em}

\clubpenalty = 10000
\widowpenalty = 10000
\displaywidowpenalty = 10000


\newcommand{\dv}{{DV}}

\begin{document}
\title{Exploring the Use of Deep Learning\\ for Feature Location}
\author{
    \IEEEauthorblockN{
        Christopher S.\ Corley
    }
    \IEEEauthorblockA{
        The University of Alabama\\
        Tuscaloosa, AL, USA\\
        cscorley@ua.edu
    }
    \and
    \IEEEauthorblockN{
        Kostadin Damevski
    }
    \IEEEauthorblockA{
        Virginia Commonwealth University\\
        Richmond, VA, USA\\
        damevski@acm.org
    }
    \and
    \IEEEauthorblockN{
        Nicholas A.\ Kraft
    }
    \IEEEauthorblockA{
        ABB Corporate Research\\
        Raleigh, NC, USA\\
        nicholas.a.kraft@us.abb.com
    }
}


\maketitle

\begin{abstract}

Deep learning models can infer complex patterns present in
natural language text. Relative to n-gram models, deep learning models can capture more
complex statistical patterns based on smaller training corpora. In
this paper we explore the use of a particular deep learning model,
document vectors (DVs), for feature location.  DVs seem well suited to
use with source code, because they both capture the influence of
context on each term in a corpus and map terms into a continuous
semantic space that encodes semantic relationships such as
synonymy. We present preliminary results that show that a feature
location technique (FLT) based on DVs can outperform an analogous FLT
based on latent Dirichlet allocation (LDA) and then suggest several
directions for future work on the use of deep learning models to
improve developer effectiveness in feature location.

\end{abstract}

\begin{IEEEkeywords}
deep learning;
neural networks;
document vectors;
feature location
\end{IEEEkeywords}

\section{Introduction}\label{introduction}
\input{sec_intro}

\section{Background}\label{background}
\input{sec_doc2vec}

\section{Preliminary Study}\label{study}
\input{sec_study}

\section{Related Work}\label{related}
\input{sec_related}

\section{Conclusions and Future Work}\label{conlusion}
\input{sec_conclusion}

%\section*{Acknowledgments}
%We acknowledge noone.

\bibliographystyle{IEEEtran-nourl}
\bibliography{doc2vec}

\end{document}
